method: grid
program: run_train.py
parameters:
  lr:
    values:
      - 0.0316
      #- 0.00316
  dataset:
    values:
      #- "mnist_ce_with_label_zero"
      #- "mnist_mse_zero_target"
      #- "mnist_ce_with_control_alignment"
      - "mnist_ce_with_loss_interpolation"
      #- "mnist_mse_with_control_alignment"
      #- "mnist_mse_with_loss_interpolation"
      #- "mnist_mse_with_random_labels"
      #- "mnist_mse_with_predictions"
      #- "mnist_with_targets"
  full_batch:
    value: False
  weight_decay_1:
    values:
      - -0.01
      - -0.008
      - -0.005
      - -0.00316
  weight_decay_2:
    values:
      - -0.316
      - -0.1
      - -0.015
      - -0.00316
      #- 0.1 not possible atm because applied to B as well
  optimizer:
    value: 'sgd'
  batch_size:
    value: 4500
  tune_for_lr:
    value: False
  mode:
    value: 'interpolate_fa_bp'
  alpha:
    values:
      - 1.0
      - 0.7
      - 0.4
  architecture:
    values:
      - 1
      - 2
  epochs:
    value: 50
  period:
    value: -1
  wandb_project:
    value: 'weight_init'
  initializer:
    value: 'lecun'
  steps:
    value: 25
  compute_alignments: 
    value : True
  lam:
    values:
      - 1.0
      #- 0.0
  jax_seed:
    values:
      - 50
      - 100